\section{Evaluation}
\label{sec:eval}

In this section, we evaluate the trade-off between the computational performance of a summarisation relation, the volume and the precision of the graph summary.
In this evaluation, we consider the following statements:
\begin{itemize}
	\item $G=\left\langle V, A, l_V \right\rangle$ is a graph;
	\item the bisimulation summary of $G$ is $\mathcal{S}_{fbt} = \left\langle \mathcal{W}_{fbt}, \mathcal{B}_{fbt}, l_{\mathcal{W}_{fbt}} \right\rangle$ according to the summarisation relation $R_{fbt}$;
	\item $\mathcal{S} = \left\langle \mathcal{W}, \mathcal{B}, l_{\mathcal{W}} \right\rangle$ is a summary of $G$ according to the summarisation relation $R$; and
	\item there exists a relation $S \subseteq \mathcal{W}_{fbt} \times \mathcal{W}$ such that $R_{fbt} \sqsubseteq R$.
\end{itemize}

\subsection{Design}

The design of this evaluation is the same as the one describe in Section~\ref{sec:eval:design}. We present here another dimension used for evaluating the precision of the summary.

\begin{quotation}
\item[\emph{Summary precision.}]

With regards to all three classification of errors, we evaluate the precision of a summary thanks to the true and false positive edges set $TP(x)$ and $FP(x)$.
We report the precision using two measures, i.e., $P1$ and $P2$.

The measure $P1$ reflects the average number of true positive edges from a randomly selected node in the inferred graph $\mathfrak{G}(R)$. From right to left, we sum the edge precisions $Prec(R, x)$ of a node $x\in \mathcal{W}_{fbt}$, which we average by the number of nodes within $C(c)$. Finally, we average over the total number of nodes within the bisimulation summary.
$$
\begin{aligned}
P1 = & \frac{1}{\vert \mathcal{W}_{fbt} \vert} \times \sum_{c \in \mathcal{W}}{\frac{1}{\vert C(c) \vert} \times \sum_{x \in C(c)}{Prec(R, x)}} \\
\text{where}\; C(c) = & \left\lbrace x \in \mathcal{W}_{fbt} \mid (x, c) \in S \right\rbrace
\end{aligned}
$$

The measure $P2$ reflects the overall chance for a randomly selected edge in the inferred graph $\mathfrak{G}(R)$ of being a true positive.
$$
P2 = \frac{\sum_{x \in \mathcal{W}_{fbt}}{TP(x)}}{\sum_{x \in \mathcal{W}_{fbt}}{TP(x) + FP(x)}}
$$
\end{quotation}

\subsection{Datasets}

The set of datasets we consider in this evaluation is the same as the one presented in Section~\ref{sec:eval:datasets}.

\subsection{Results}

We evaluate and compare in this section the different graph summary algorithm according to the precision. Then, we discuss the trade-offs with respect to the three dimensions, i.e., the precision we discuss in this section, and the performance and volume dimensions discussed in Section~\ref{sec:summary:eval}.
We note the mean of measurements in a category as $\mu_{L}$, $\mu_{M}$, $\mu_{H}$, and $\mu_{VH}$, respectively.

\subsubsection{Graph Summary Precision}

We discuss in this section the precision of a summary with regards to the connectivity first, then to the type and attribute next. We do not report the precision in any error classification for the \texttt{dbpedia} dataset. The reason is we were unable to evaluate the precision on it due to performance issues. While the performance evaluation did not account for the sumnode $\mathfrak{U}$ of undefined mappings, we do consider it for the precision evaluation.

\minisec{Connectivity Precision}

The Table~\ref{tab:precision-conn} reports the connectivity precision results $P1$ and $P2$. For each category of dataset complexity, we report the mean $\mu$ of the connectivity precision.

The summarisation relations based only on the type feature, i.e., $R_{st}$ and $R_t$, provide a low connectivity precision. Indeed, they show on average a connectivity precision of $25\%$ according to $P1$, i.e., $\mu_H=0.2414$.

Summarisation based on the attribute feature only provide also a low precision on \emph{Medium} and \emph{High} categories. On the \emph{Low} category, the attribute feature exhibits a better precision than the type feature, i.e., $\mu_L=0.5579$ against $\mu_H=0.3617$. However, when the type and attribute features are combined in $R_{at}$, it provides a significant increase of the precision. According to $P1$, we reach on average a $50\%$ connectivity precision ($0.5124$) on the \emph{High} category for $R_{at}$, and at least $20\%$ on \emph{Medium}.

We remark that the incoming attribute in $R_{ioa}$ is an important feature that increases the precision. The $R_{ioa}$ summarisation provides a precision of $30\%$ on the \emph{Medium} up to $50\%$ on \emph{High}, whereas $R_a$ reaches $15\%$ on \emph{Medium} and $10\%$ on \emph{High}. Overall, we can achieve a good average connectivity precision with $R_{ioat}$ according to $P1$. However, the overall precision $P2$ is very low on the datasets of \emph{Medium} and \emph{High} complexities. This suggests that few nodes of the summary have a high out-degree, creating a combinatorial explosion of false positive edges. This will be investigated in future work.

\input{04-summary/experiments/link-precision}

\minisec{Schema Precision}

The Table~\ref{tab:precision-schema} reports the means $\mu$ for a category of dataset complexity of the type and attribute precisions results $P1$ and $P2$, i.e., regarding the schema of the summary.

The summarisation $R_{st}$ and $R_t$ based on the type feature provide an attribute precision above at least $60\%$ for $P1$ ($\mu_M=0.5927$ for $\sim_{st}$).
On the contrary, the attribute feature reports a good type precision, reaching on average at least $90\%$ for $R_a$, i.e., $P1=0.9222$ on the \emph{Medium} datasets.

Incoming attributes do not increase much the type precision, since the type precision of $R_a$ stays on par with $R_{ioa}$. The $R_{at}$ relation provides a perfect summarisation of the graph schema. Again, the significant differences between $P1$ and $P2$ suggests one more time that few nodes of the summary contains a high out-degree, creating a combinatorial explosion of false positive edges.\\

\input{04-summary/experiments/schema-precision}

In conclusion, we observe that a combination of both type and attribute features is necessary to achieve a good precision. The results show that taking incoming attributes as a feature of the summarisation relation is important for the connectivity precision, but not for the schema.

However, there is place for improvement for overall connectivity precision especially on certain datasets. We observe that the precision $P2$ leads to very low precision values which is caused by a few summary nodes with a high out-degree. This indicates that the model of $P2$ is not appropriate for measuring the precision of a summary in terms of connectivity and schema.

\subsubsection{Trade-Offs}

We report in Figure~\ref{fig:trade-conn-volume} the trade-off between the average connectivity precision and the average volume ratio across all datasets among all the relations. We can distinguish two groups of relations, the type-based summarisations, i.e., $R_t$ and $R_{st}$, and the attribute-based ones.
The type-based relations provide the best volume ratio, but also the worst precision. In the attribute group, the volume ratio among relations is close to each others, but their precision differs greatly, with $R_{ioat}$ ahead. This suggests that in terms of trade-off between connectivity precision and volume, $R_{ioat}$ is the best candidate.

We report in Figure~\ref{fig:trade-schema-volume} the trade-off between the average schema precision and the average volume ratio across all datasets among all the relations. Again we can distinguish the same two groups. However, in the attribute group, the precision does not differ too much among the candidates, each one being either equal or very close to $1$. In the type group, the \emph{Types} summarisation relation $R_t$ provides a quite reasonable precision for a very small volume ratio. This suggests that if the precision is primordial, the \emph{Attributes \& Types} relation $R_{at}$ is the best candidate, providing a perfect schema precision for the smallest volume. However, if volume is primordial instead and that some imperfection can be tolerated, then the \emph{Types} summarisation relation $R_t$ is the best candidate.

We report in Figure~\ref{fig:trade-conn-cpu} (resp., \ref{fig:trade-schema-cpu}) the trade-off between the average connectivity precision (resp., average schema precision) and the average CPU time across all datasets among all the summarisation relations. Among the attribute-based algorithms $R_a$, $R_{at}$, $R_{ioa}$ and $R_{ioat}$, the latter is the one that achieves the best runtime with the highest precision. Among the type-based algorithms, the \emph{Types} summarisation $R_t$ achieves a lower runtime and a higher precision than the \emph{Single-Type} relation $R_{st}$.
If the schema precision is primordial and a low connectivity precision can be tolerated, the \emph{Types} summarisation $R_t$ is the best candidate as it provides a high schema precision, with the best CPU time. On the contrary, if the connectivity is primordial, the summarisation relation $R_{ioat}$ is the best candidate, but this at the cost of a longer runtime.

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.46\textwidth}
		\resizebox{\textwidth}{!}{
			\input{04-summary/experiments/tradeoff-volume*conn}
		}
		\caption{Connectivity precision versus volume ratio.}
		\label{fig:trade-conn-volume}
	\end{subfigure}
	\qquad
	\begin{subfigure}[t]{0.46\textwidth}
		\resizebox{\textwidth}{!}{
			\input{04-summary/experiments/tradeoff-volume*schema}
		}
		\caption{Schema precision versus volume ratio.}
		\label{fig:trade-schema-volume}
	\end{subfigure}
	\qquad%
	\begin{subfigure}[t]{0.46\textwidth}
		\resizebox{\textwidth}{!}{
			\input{04-summary/experiments/tradeoff-cpu*conn}
		}
		\caption{Connectivity precision versus summarisation performance.}
		\label{fig:trade-conn-cpu}
	\end{subfigure}
	\qquad%
	\begin{subfigure}[t]{0.46\textwidth}
		\resizebox{\textwidth}{!}{
			\input{04-summary/experiments/tradeoff-cpu*schema}
		}
		\caption{Schema precision versus summarisation performance.}
		\label{fig:trade-schema-cpu}
	\end{subfigure}
	\caption{Efficiency and precision trade-offs of the candidate summarisation relations. The values are taken as the average across all dataset categories.}
\end{figure}
