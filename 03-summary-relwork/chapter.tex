\chapter{Graph Summarisation: Related Work}
\label{chap3:review}

In many Computer Science areas, the information is represented as and is analysed through graphs. Graphs are used to capture the social relationship between people, to represent processes and their transition in concurrency, or to structure data in a flexible way, e.g., using the Object Exchange Model \cite{papakonstantinou:1995:oea} or, more recently, the Resource Description Framework \cite{rdfconcepts}.\\

A common challenge encountered when analysing a graph is its size. A large number of nodes or edges increases the running time of algorithms applied on the data. A solution is to \emph{map} the graph into another, smaller graph while preserving its structure. That process is a graph homomorphism, which is commonly called \emph{graph summarisation} and the resulting graph is then considered as a \emph{summary} of the entity graph.

In addition to the challenge of the graph size, we consider also the other challenge of the graph structure being partially or totally unknown. As discussed in Section~\ref{chap:introduction:data-mgmt}, although a dataset might adhere to an ontology, in general it cannot be used to understand the structure of that dataset, a possible reason being either
\begin{inparaenum}[(a)]
\item the dataset is a mashup of several data sources, each following a different ontology --- therefore, there is no ontology that describes the combined dataset; or
\item the dataset is originally built from a variety of ontologies in order to fulfill modelling requirements.
\end{inparaenum}
Therefore, a graph summarisation can then be used for shedding light on the structure of the graph, which can hold a function similar to a \emph{schema} in databases.\\

Depending on the kind of interaction with the summary, a different level of details is needed. Intuitively, it is conceivable that a graphic application may require less information about the data compared to a query optimisation application. We present in this chapter the scientific literature on graph summarisation. The research works are ordered by the increasing level of details needed in the summary by the respective use case applications.

\section{Dimensions of Graph Summarisation Challenges}

In the computer science literature, we see the graph summarisation technique being employed to face a performance challenge. Some graphs are too large to be processed in a reasonable time or to fit into the main memory. A solution is to substitute that graph with another that is significantly \emph{smaller}, thus improving the application's performance. Questions that can be raised are
\begin{inparaenum}[(a)]
\item in which aspect is the summary smaller than the graph; and
\item what properties of the graph influence the summary.
\end{inparaenum}
In this section, we present three dimensions through which we discuss the literature on graph summarisation in the rest of this chapter:
\begin{enumerate}
\item the \emph{size} of the graph;
\item the \emph{size} of its summary; and
\item the impact of the graph's \emph{heterogeneity} on the summary.
\end{enumerate}
The Figure~\ref{fig:gs-axis} depicts the dimensions which form a three-dimensional space, within which a graph summarisation approach is located. For example, an approach might produce a summary which size increases as the graph gets more heterogeneous.

\begin{figure}
	\centering
	\resizebox{.5\textwidth}{!}{
		\input{03-summary-relwork/figures/axis}
	}
	\caption{Graph summarisation dimensions}
	\label{fig:gs-axis}
\end{figure}

\paragraph{Size of the graph.}

It is desirable for a summary to be smaller than the entity graph, since it is generally its substitute for performance reason. We measure the ``complexity'' of a graph by its number of edges. The rationale is that the more a graph has edges, the more difficult it is to process since it requires more computational power and memory.
%We introduce the \emph{volume} as a way for measuring how complex a graph is, and is computed from the numbers of nodes and edges in the graph.
%
%\begin{definition}[Graph Volume]
%Let $G=\left\langle V, A, l_V \right\rangle$ be a graph.
%We call $Vol(G)$ the \emph{volume} of the graph $G$, and is equal to the sum of the size and order of $G$:
%$$
%Vol(G) = \vert A \vert + \vert V \vert
%$$
%\end{definition}

\paragraph{Graph heterogeneity.}

We consider a graph to be heterogeneous when it is not consistent with regards to
\begin{inparaenum}[(a)]
\item its structure; and
\item its labelling.
\end{inparaenum}
Our rationale is that the more heterogeneous an entity graph is, the more difficult it is to create a \emph{precise} and \emph{concise} summary of that graph. By precise, we mean a summary which description of the entity structure of the graph is accurate. By concise, we mean a summary of small size.

For example, we can imagine a dataset describing people in which the attributes are not consistent from a person to another: in one the phone number is missing, while in another it is the birth place. The Figure~\ref{fig:graph-hetero} illustrates the two scenari of graph heterogeneity, where we depict possibles graph summarisation with a \textit{dashed} graph.

\subparagraph{Heterogeneity of the graph structure.}

Figure~\ref{fig:hetero-struct} depicts a graph in which the structure is inconsistent. The node $a_0$ has two incoming edges and a single outgoing edge, while for the node $b_0$ it is the opposite: a single incoming edge and two outgoing. Although the depicted summary in dashed lines may be considered sufficient, it loses some \emph{information} about the graph. We may record the in/out-degrees as \emph{metadata} but this requires additional storage space.

\subparagraph{Heterogeneity of the vocabulary.}

Considering our previous example of the people dataset, a graph can be seen as heterogeneous if it uses different attributes for each entity within. Figure~\ref{fig:hetero-voc} depicts a graph in which this is the case: entities $a_1$, $\cdots$, $a_n$ have a different attribute each. A possible summarisation would be to create an isomorphic graph, i.e., edges of both graphs can be mapped to one another, but then the summarisation purpose --- to substitute the graph with another more manageable --- is lost. Another summarisation is depicted on the right as a dashed graph, where two nodes $s_a$ and $s_b$ are linked with all $n$ attributes. Although this reduces the number of nodes from $2 \times n$ to $2$, we loose the original distribution of the attributes.\\

In the rest of this chapter, we discuss the graph summarisation literature with regards to those three dimensions.

\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\resizebox{\textwidth}{!}{
			\input{03-summary-relwork/figures/structure-heterogeneity}
		}
		\caption{Graph structure heterogeneity}
		\label{fig:hetero-struct}
	\end{subfigure}
	\qquad
	\begin{subfigure}{.42\textwidth}
		\resizebox{\textwidth}{!}{
			\input{03-summary-relwork/figures/voc-heterogeneity}
		}
		\caption{Graph vocabulary heterogeneity}
		\label{fig:hetero-voc}
	\end{subfigure}
	\caption{Graph heterogeneity where the dashed graphs represent possible summaries of the graph}
	\label{fig:graph-hetero}
\end{figure}

\section{Graph Summarisation Approaches}

%% present here the different kinds of approaches
The concept of graph summarisation has been explored for diverse use cases in the literature. In Section~\ref{chap03:review:graph-exploration}, we present some research where it has been employed for aiding a user in exploring an unknown graph. In Section~\ref{chap03:review:query-profiling}, a summary of the graph is used for profiling the data, i.e., gathering some statistics about the graph so to analyse it with regards to upstream applications such as data integration. Graph summarisation is also used for analysing the \emph{content} of the graph by computing aggregates, which research is discussed in Section~\ref{chap03:review:data-analytics}. As discussed in Section~\ref{chap03:review:query-optim}, graph summarisation has been used for the purpose of optimising the query evaluation by outlining what paths exist in the graph and creating indices over the summary.\\

Figure~\ref{fig:timeline} depicts a time-line of the literature presented in this chapter. The main use case of each work is indicated with a trapeze having its own colour and stripes; a trapeze reflects the sections outlined in the previous paragraph. From the time-line, we observe that graph summarisation was at first used for optimising query evaluation through indices; a new direction later appeared where the summary is used for analysing and exploring a graph. This new direction might be linked with the emergence of Web Data, since users generally interact with graphs which structure is (partially) unknown.

\paragraph{Graph clustering versus graph summarisation.}

Both techniques are similar in the sense that they partition the graph.
Clustering is the process of finding the underlying structure of a dataset by grouping elements that are \emph{similar} to each other. A group is then called a cluster. In the context of a graph, a clustering technique in general seeks clusters of nodes that have many connections to each other \emph{within}, but few \emph{between} the clusters. Schaeffer presents in \cite{schaeffer:2007:graph} a survey of graph clustering approaches. Instead, with graph summarisation techniques we aim to partition the graph in such a way that the original structure of the graph is preserved.

\paragraph{Graph summarisation vocabulary.}

We explain in this paragraph several terms that we use henceforth when discussing about graph summarisation.
Given a graph $G = \left\langle V, A, l_V \right\rangle$, the process of graph summarisation creates another graph, called the \emph{summary} of $G$. Each node of $G$ is mapped to one or more nodes of the summary, which we call \emph{sumnodes}. Similarly, edges of the graph $G$ are also mapped to edges in the summary, which we call \emph{sumedges}. The goal of the graph summarisation is to create a summary where the structure of the entity graph $G$ is preserved.

\begin{figure}
	\resizebox{\textwidth}{!}{
		\input{03-summary-relwork/figures/timeline}
	}
	\caption{Time-line of the research on graph summarisation}
	\label{fig:timeline}
\end{figure}

\section{Graph Exploration}
\label{chap03:review:graph-exploration}

Graph summarisation techniques can be used for exploring a graph. In this scenario, the structure of the graph is (partially) unknown; it is necessary however to know it in order to compose queries over the graph. The user leverage the summary to learn what attributes are used, what types, and how they relate with each other. In the time-line, the research works for this application are depicted with a red horizontally-striped trapeze in Figure~\ref{fig:timeline}.\\

Tian et. al \cite{tian:sigmod:2008} propose the use of graph summarisation for exploring a graph: by grouping nodes that share some pre-defined criteria, the ``general'' structure of the graph is brought out. The coarseness of the grouping can also be tuned so to retain more or less details about the graph. This work is a bridge to the OLAP (online analytical processing) world, since it allows OLAP-style exploration of the graph by providing drill-down and rollup operations. The user can drill-down, i.e., view more details about the structure of the graph, and rollup, i.e., browse a more abstract view of the structure of the graph. This is made possible by showing a \emph{summary} of the graph at each level of detail in the drill-down/rollup exploration.

The proposed approach creates a summary graph by mapping each node of the graph into exactly one sumnode; several nodes can map to a same sumnode in the summary. Two nodes are mapped to a same sumnode if they share the same
\begin{inparaenum}[(a)]
	\item attributes' value; and
	\label{chap3:review:acompatible}
	\item incident sumnodes of a node maps to.
	\label{chap3:review:rcompatible}
\end{inparaenum}
The algorithm first partition the graph in order to achieve (\ref{chap3:review:acompatible}), then iteratively splits each block (sumnode) in the partition until each node in a sumnode fulfils (\ref{chap3:review:rcompatible}). The latter step relies on the incident matrix between nodes in the graph and sumnodes in the summary to decide whether to split a sumnode or not; there is one such matrix per attribute. A cell $a_{i,j}$ of the matrix is equal to $1$ if a node on row $i$ maps to a sumnode which is a neighbour of the sumnode on column $j$, otherwise it is equal to $0$.

The algorithm requires several passes over the graph in order to fulfill (\ref{chap3:review:rcompatible}). For large graphs that do not fit in memory, this becomes a challenge in itself. Indeed, if some part of the graph is not in memory, it needs to be retrieved, e.g., from disk, which would impact negatively on the algorithm performance.

The authors extend this work in \cite{zhang:2010:ddg} where a measure for the ``interestingness'' of a graph summary is proposed. The aim of this measure is to quantify how easy it is for a person to visualise and understand the high-level structural characteristics of the graph. 

\begin{centeremph}{Our contribution}
In Chapter~\ref{chap5:precision}, we argue that the interestingness of a summary actually depends on the application it is used for. In \cite{zhang:2010:ddg} the authors also investigate how to summarise numeric data; while this is an important aspect of graph summarisation in some application, we focus in this thesis on summarising the structure of the graph.
\end{centeremph}

Liu et. al \cite{zheng:ipsj:2011} propose a graph summarisation that \emph{approximates} the information in the entity graph, i.e., the structure of the graph and the attributes' value associated with a node. The authors aim to construct a summary that is \emph{homogeneous}, i.e., each node mapped to a sumnode of the summary are consistent with one another. Three criteria that measure different aspect of the summary homogeneity are introduced:
\begin{itemize}
	\item all nodes mapped to a sumnode have the \emph{same} attributes' value;
	\item a sumedge $(a,\alpha,b)$ implies that \emph{all} nodes in the sumnode $a$ are connected to at least one node in $b$; and
	\item all nodes mapped to a sumnode must have the same \emph{degree}\footnote{Degree is the number of nodes adjacent to a node.}.
\end{itemize}
The quality of a criterion is measured using the entropy. A summary built with all three criteria fulfilled can be approximated --- so to achieve a smaller size --- by relaxing a criterion.

Two algorithms are presented for creating an approximate summary. The first one is an agglomerative approach which starts from the \emph{exact} graph partition according to the three criteria, then proceeds to merge sumnodes until reaching a pre-defined number of sumnodes. At each iteration, the merged sumnodes are those that would results in minimal entropy. The second algorithm instead relies on a K-Means clustering of the graph and \emph{split} sumnode until a pre-defined number of sumnodes is reached.

\begin{centeremph}{Limitations}
	The first algorithm presents the challenge of starting from the exact partition, which is computationally expensive as it requires several iterations over the graph. Both algorithms use a pre-defined number of sumnodes, although a user probably has no idea what number to choose.
\end{centeremph}

The authors in \cite{konrath:jws:2012} propose a three-layer index on top of the Linking Open Data (LOD). Each layer provides a view on the data with varying details. Ultimately, the index allows to select data sources that are relevant for a SPARQL query. The selection is driven by the three layers of the index, where a layer is more suited to a query of specific complexity.
Each layer of the proposed index provides views of the LOD graph with varying granularity: the lower the layer, the more detailed it is.

\begin{centeremph}{Our contribution}
	A layer can be considered as a possible summarisation of the LOD graph, although connections between sumnodes within a layer is not provided. The proposed index model is then orthogonal to our graph summarisation model, each layer being a summary itself.

	We note that the third layer which is the most detailed one is based on \emph{bisimulation}; however, the definition used in that work is not the commonly used one, which we present in Section~\ref{chap4:summary:bisim}.
\end{centeremph}

%\begin{itemize}
%\item \cite{tian:sigmod:2008} proposes an approach based on bisimulation that provides more or less detailed summaries. However, the level of detail is left to the user; this assumes some  prior knowledge about the data structure and content. Bridge between OLAP and graph summarisation.

%- support for multi-valued attributes: essential for rdf:types
%- the attributes' value are also taken into consideration when creating groups of nodes.
%  - ex of 2 graphs with different attribute values but similar graph structure.
%  - for web data, this can increase the size of the summary
%- only direct relationships are considered for grouping nodes.
%- can be modelled using our approach as it is a graph homomorphism.
%- Iteration approach: initialise grouping based of A-compatible, then split groups until the grouping is (A,R)-compatible.
%- neighbor group bitmap is the incidence matrix between nodes and group. There is such a matrix for each edge label ~~ with heterogeneity.

%* nodes - LB=nb of distinct attributes' value groups	UB=nb of nodes orig

%\item \cite{zhang:2010:ddg} addresses two shortcomings of \cite{tian:sigmod:2008} by supporting numerical data and proposing an ``interestingness'' measure of a graph summary. That measure helps a user to find the best resolution of the summary.

%\item An Information Theoretic approach to graph summarisation is presented in \cite{zheng:ipsj:2011}. The authors propose three criteria for defining the homogeneous property of a graph. A criterion can then be relaxed in order to produce a smaller (approximate) graph summary. The technique seeks to lower the entropy of the graph summary, hence ensuring a good quality.
%\end{itemize}

\section{Data Profiling}
\label{chap03:review:query-profiling}

A graph summarisation algorithm can be used for providing insights into a graph by accumulating some statistics during the summary construction process. In the time-line of Figure~\ref{fig:timeline}, literature pertaining to this use case are depicted with a red dotted-trapeze.\\

Khatchadourian et. al \cite{khatchadourian:2010:eswc} describe the structure of the graph along with statistics thanks to summaries. The proposed summary is built using the bisimulation equivalence, which is described in Section~\ref{chap4:summary:bisim}.

\begin{centeremph}{Our contribution}
	The presented approach is tailored towards graphs using specifically the RDF data modelling; instead, we present a graph summarisation framework that is independent of the graph modelling.

	The authors consider a directed graph where only nodes are labelled: each label in our graph model presented in Section~\ref{sec:gdm:formal-model} forms a node. We use instead the same graph model for both the entity graph and for the summary graph, thus simplifying the framework.

	The labelling scheme proposed in \cite{khatchadourian:2010:eswc} of sumnodes and sumedges is limiting, since it considers only parts of the resources' URI in the entity graph, e.g., the localname. The set of labels thus constructed is too small for finely controlling how much information from the graph is retained. To add more flexibility, we decouple the definition of a node from the creation of its label, where the former is discussed in Section~\ref{chap4:summary:model} and the latter in Section~\ref{chap4:summary:algo}.

	The authors discuss the summarisation of \emph{inter-linked} datasets through the use of specific labelled edges, i.e., \emph{owl:sameAs} edges. Instead, we consider in this scenario the dataset label, which we detail in Section~\ref{chap03:summary:impl:inter-datasets}.
\end{centeremph}

Navlakha et. al \cite{navlakha:2008:gsb} propose a graph summarisation approach based on Information Theory. The result of the approach is the creation of two data structures, i.e., the summary graph and a set of corrections. The set of corrections allows to rebuild the entity graph by correcting any error in the summary graph, e.g., an instance of a sumedge links two \emph{disconnected} nodes in the entity graph. The algorithm is based on the minimum description length \cite{grunwald:2007:mdl} principle which aims to minimise the cost of the summary representation of the graph, i.e., the sum of the summary's size and of the corrections' set size.
The size of the summary can be further reduced by allowing some errors; there is then a trade-off between the precision and the size of the summary.

\begin{centeremph}{Our contribution}
	In contrary, we do not attempt to rebuild the entity graph from the summary and so we focus on summarising the structure of the graph.
\end{centeremph}

Liu et al. \cite{liu:cikm:2014} present a graph summarisation approach based on the \emph{Message Passing} paradigm. The algorithm iteratively merges nodes of the graph until a predefined number of nodes are left; the merged nodes constitute then the sumnodes of the summary. Several solutions for selecting which nodes to merge are discussed, and a method based on \emph{Locality Sensitive Hashing} \cite{gionis:1999:ssh} is introduced so to improve the merging process.

A sumedge indicates in this approach that all nodes that are mapped to the adjacent sumnodes are connected to each other as well. A subset $A \subset V$ of nodes in the graph are mapped to a sumnode $a$, and similarly, a subset $B \subset V$ of nodes are mapped to a sumnode $b$; then, the existence of a sumedge $(a,\alpha,b)$ in the summary means in this approach that every node in $A$ is also connected to a node in $B$. In order to reduce the size of the summary, this requirement can be relaxed when merging: the merge that incurs the less error is chosen.

\begin{centeremph}{Our contribution}
	In comparison, our framework simplifies the graph summarisation process thanks to its summary definition. Since it is based on graph homomorphism, we know exactly to which sumnode a node of the graph is mapped to; therefore, our graph summarisation is not an iterative process, hence simplifying the overall execution.
\end{centeremph}

%\begin{itemize}
%\item A system for the discovery of datasets is proposed in \cite{khatchadourian:2010:eswc}.
%- the presented approach is tailored towards RDF graphs. we present a graph summarisation model that is independent of the graph modelling.
%- the labelling scheme is limiting, it considers only parts of the URI, e.g., the localname. the set of labels for the sumnodes and sumedges is too small for controlling how much information from the graph is retained. (explain pb with available\_as)
%- discuss summary of inter-linked datasets based on sameas links. instead we consider the context of statements when summarising inter-linked datasets.
%\item The authors of \cite{navlakha:2008:gsb} propose a summarisation based on the Information Theory principle of Minimum Description Length. Although the original data graph can be re-created from the summary, a user-defined bounded error parameter can be used to balance the summary volume with the loss in precision.
%\end{itemize}

\section{Data Analytics}
\label{chap03:review:data-analytics}

OLAP (online analytical processing) is a technique for answering analytical queries over multi-dimensional data. Through different kind of operations it allows a user to analyse the data from different perspectives. Each perspective is called a \emph{cube}, obtained by aggregating the values of some dimensions. In the time-line of Figure~\ref{fig:timeline}, the research works that pertain to this use case are depicted with a plain grey trapeze.\\

Several works investigate the use of OLAP over graphs: data records analysed through OLAP are now related to each other. The main difference between traditional OLAP and graph-OLAP is the \emph{measure} which traditionally is a number becomes a \emph{graph}. Compared to \cite{tian:sigmod:2008} discussed in Section~\ref{chap03:review:graph-exploration}, the works presented here are anchored in a OLAP background, rather than being a bridge to OLAP from the graph exploration domain.

\begin{centeremph}{Observation}
	Among the possible OLAP operations, \emph{rollup} and \emph{drill-down} control the level of details presented to the user about the graph. With regards to our graph summarisation presented in Chapter~\ref{chap4:summary}, each level is actually a summary. Therefore, the approaches of OLAP over graphs are orthogonal to ours.
\end{centeremph}

Chen et. al propose in \cite{chen:icdm:2008} two OLAP frameworks \emph{I-OLAP} and \emph{T-OLAP} for analysing graphs. The I-OLAP aggregation is aimed at summarising several graphs representing a same entity. It is then a merge of the graphs that keeps the entity layer, while we rather consider the summarisation of the structure of the graph which is a different view on the graph. The T-OLAP framework, which is further investigated in \cite{qu:dasfaa:2011}, modifies the \emph{topology} of the graph. T-OLAP maps nodes into sumnodes according to their attributes' value, and computes a statistic for the sumnode using an aggregate function, e.g., \emph{count}.

\begin{centeremph}{Our contribution}
	Compared to our graph summarisation, the authors consider the attributes' value while we do not require those.
\end{centeremph}

Zhao et. al \cite{zhao:sigmod:2011} present a framework for analysing multi-dimensional graphs. Rooted in the OLAP domain, the framework retains the relationships between nodes, information which is normally discarded in traditional OLAP. The work presents the summary as the output of a query over the graph, which aggregates nodes sharing a fixed set of attributes' value.

\begin{centeremph}{Our contribution}
	The proposed framework considers a graph with a fixed set of attributes. However, we consider a graph which vocabulary and structure is heterogeneous. Therefore, it is unlikely the graph can be effectively collapsed over a pre-defined set of labels; instead we propose a model that can handle the heterogeneity of the graph.
\end{centeremph}

The summary in \cite{zhao:sigmod:2011} is defined based on an equivalence relation; two nodes of the graph are equivalent if they share the same attributes' value. The equivalence relation forms classes, which stand for the sumnodes of the summary; two sumnodes are connected if any node they contain are connected in the graph.

\begin{centeremph}{Our contribution}
	We propose instead a framework based on graph homomorphism which is more expressive in the definition of the summary.
\end{centeremph}

Figure~\ref{fig:graph-cube} depicts the summarisation of a graph as per \cite{zhao:sigmod:2011}; it presents three sumnodes $S_1$, $S_2$, and $S_3$, in which nodes of the graph they are associated with are represented as a cross. Every node in a sumnode is equivalent to one another; however, this does not affect the connectivity between the sumnodes as $S_2$ and $S_3$ are linked although only two of their nodes out of five actually are.

\begin{centeremph}{Our contribution}
	In our framework, conditions affecting the connectivity in the summary can be defined explicitly if needed. Furthermore, the graph homomorphism is also a more natural definition of the summary, since homomorphism is an operation that retain the structure of the graph.
\end{centeremph}

\begin{figure}
	\centering
	\resizebox{.5\textwidth}{!}{
		\input{03-summary-relwork/figures/graph-cube}
	}
	\caption{Graph summarisation based on equivalence relation as in \cite{zhao:sigmod:2011}}
	\label{fig:graph-cube}
\end{figure}

Colazzo et al. \cite{colazzo:www:2014} describe a framework for using OLAP over RDF data. Each cube represents a summary and is built based on SPARQL queries which define sumnodes and sumedges. This analytical framework is flexible enough to accommodate many kinds of analysis, since the aggregate function is also based on a SPARQL query. Although the analysis of the data is done through its cubes by a user, the computation of a cube is always done over the original data.

\begin{centeremph}{Observation}
 	The need of writing SPARQL queries suggests that a user possesses some knowledge about the structure of the graph. This work is orthogonal to the one proposed in this thesis: our approach highlights the graph structure, thanks to which a deeper analysis of the graph can be done.
\end{centeremph}

Wang et al. generalise the concept of OLAP over graphs in \cite{zhengkui:2014:ppg} by proposing a property graph model and allowing to summarise over the properties associated with edges and/or nodes; a property graph model is a graph where a node and an edge is associated with a list of property-value pairs.

\begin{centeremph}{Our contribution}
	This approach focuses on summarising the graph based on the values of a pre-defined set of attributes; instead, we consider graphs that are heterogeneous and also possibly with multi-valued attributes.%, for which our graph summarisation framework is more adapted.
\end{centeremph}

The generalised graph OLAP approach \cite{zhengkui:2014:ppg} is implemented over a MapReduce \cite{dean:2008:msd} framework. It leverage the lattice graph of all the possible summaries in order to generate several summaries in a single task in the MapReduce framework. A best execution plan for the series of MapReduce jobs is found using a cost model.

\begin{centeremph}{Our contribution}
	In this thesis, we show how the \gls{lattice} graph can also be used for the purpose of evaluating the precision of a summary in Section~\ref{chap5:precision}.
\end{centeremph}

Rudolf et al. \cite{rudolf:2013:slg} propose a framework for analysing graphs through \emph{templates}. The graph is summarised given user-defined graph \emph{patterns}, which are then matched over the graph. An aggregation function is finally applied over the set of matched sub-graphs, e.g., a \emph{count} function.

\begin{centeremph}{Our contribution}
	This approach requires the user to have some knowledge about the structure of the graph for performing the summarisation; instead, our framework does not assume any prior knowledge.
\end{centeremph}

\section{Query Optimisation}
\label{chap03:review:query-optim}

The purpose of the graph summarisation is to create a graph that share the same structure as the original, but is significantly smaller. Hence, that summary can be used in place of the original in order to improve the speed of query optimisation. In the time-line of Figure~\ref{fig:timeline}, the literature that pertain to this application of the summary are depicted with a blue vertically-striped trapeze.\\

DataGuides \cite{goldman1997dataguides} is the first work to improve the query execution through the use of an index on the summary of the structure of the graph. The summary is built with the requirement that every path in the summary is \emph{unique}; this would allow to spend less time searching through each different path. In the presence of a graph with a complex structure, the size of the summary can be as large as the graph, or even larger. This issue is discussed in \cite{goldman1999approximate}, where some constraints of DataGuides are relaxed, e.g., the existence of a path in the entity graph.\\

DataGuides relies on the notion of automata for the creation of the summary: converting a graph that is a non-deterministic finite automaton to a deterministic finite automaton. Instead, several works leverage the notion of bisimulation~\cite{park:1981:cai} used in concurrency systems.
Bisimulation is a technique that aims to replicate all the paths of a graph in a summary, so that the summary and the original graph cannot be distinguished from a user's perspective. A detailed explanation of this technique can be found in Section~\ref{chap4:summary:bisim}.
Retaining all the paths of the original graph in the summary can reveal to be excessive for complex graphs. Therefore, some constraints of the bisimulation are changed so to reduce the size of the summary, or to better adapt it to a specific application. The size of a summary is then balanced against the level of details it stores.

Milo et. al \cite{Milo:1999:ISP:645503.656266} extend the work on DataGuides, using the notion of bisimulation to build an index of the structure of the graph. The authors propose to reduce further the size of a summary by defining the shape of query to answer. However, it assumes some knowledge about the structure of the graph in order to define the shape of the query.

The constraints of the bisimulation relation are relaxed so to achieve a smaller summary: Kaushik et. al \cite{kaushik:de:2002} propose a graph summarisation approach where the bisimulation is simplified by limiting the length of a path to $k$-hops. In parallel, Kaushik et. al \cite{kaushik:2002:cib} create an index of paths expressions, based on a summary that has been built for a pre-defined query expression.
Chen et. al \cite{chen:2003:dia} propose instead to vary the maximum length of a path per node, depending on the query load of the system. Polyzotis et. al \cite{polyzotis:2006:xsx} propose a system that relies on the notion of bisimulation for estimating cardinalities necessary during query evaluation.

Tran et. al \cite{Tran:2012:kde} use a similar approach to \cite{kaushik:2002:cib} for improving the partitions of RDF data and the execution of queries. The data is partitioned into groups that have a similar structure so to reduce
\begin{inparaenum}[(a)]
\item the communication load during query evaluation; and
\item the number of joins.
\end{inparaenum}

Riondato et al. \cite{riondato:2014:gsq} present a graph summarisation approach that bridges to graph clustering. The summarisation is expressed as an optimisation problem, where an error function is to be minimised. The function measure the error for reconstructing the entity graph from the summary. This function is expressed as the matrix distance between the adjacency matrices of the graph and its summary. The number of nodes in the summary is set as a parameter to the algorithm, which can be difficult for the user to decide which value to choose.\\

\begin{centeremph}{Our contribution}
	We propose in this thesis a generic graph summarisation framework in which the summarisation is defined based on different features of the graph, e.g., attributes or types. No a priori knowledge about the graph is required, neither is it necessary to specify the number of sumnodes to reach. The features used for defining the summarisation can be tuned so to achieve a smaller summary, sacrificing as little as possible the amount of details recorded about the entity graph.
\end{centeremph}

%\section{Graph Schema Creation via Graph Summarisation}
%
%\section{Large-scale Computation}
%\label{chap03:review:large-scale-comp}

\section{Summary}

In this Chapter, we reviewed the literature related to graph summarisation and compared it with our framework that we present in Chapter~\ref{chap4:summary}. We outline in this section the core differences between our and the presented approaches to graph summarisation.

\begin{labeling}{\textbf{Expressiveness.}}
	\item[\textbf{Expressiveness.}] The presented graph summarisation algorithms are designed for specific applications, and can then be difficult to port. We present a flexible and expressive graph summarisation based on graph \emph{homomorphism}.

	The definition of the summarisation simply needs the user's specification of how a node in the graph is mapped to a sumnode. The mapping is simply based on \emph{features} of a node. In addition, since our summarisation is based on homomorphism, the mapping process of a sumnode to a node is deterministic; there is no need to specify properties of the summary in advance, e.g., the number of sumnodes.
	\item[\textbf{Performance.}] Graph summarisation algorithms require to visit each edge of the entity graph at least once. In order to improve the quality of the summary, some approaches \cite{zheng:ipsj:2011} perform several iterations over the graph. Iterations are necessary when the summarisation of a node also depends on nodes that are not directly connected to it, and so there is a need to traverse the graph. The larger the graph is, the more expensive it is to iterate over the graph. While such algorithms can be expressed in our framework, it is not a necessity in order to summarise a graph.
	\item[\textbf{Generic.}] We present a generic graph summarisation approach that can be used as a base in a variety of applications. For example, a summary is core to drill-down/rollup operations in OLAP over graphs.
\end{labeling}

%\begin{itemize}
%\item algorithms with iterations
%\item need to know the final number of sumnodes
%\item graph summarisation approaches that consider attributes' value: T-OLAP in \cite{chen:icdm:2008}, SPAN in \cite{tian:sigmod:2008}. This is not mandatory in our framework.
%\item our graph summarisation framework is flexible in the summary construction, since it is based on graph homomorphism and the definition of the relation is left to the user.
%\item multi-valued attributes is not taken into account by the presented approaches.
%\item graph summarisation can be used as a step stone for several applications, e.g., it is the basis for applying OLAP operations over a graph.
%\end{itemize}
